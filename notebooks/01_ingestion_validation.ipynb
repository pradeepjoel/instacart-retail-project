{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceaac4aa-813c-4d4e-82a5-9205836a58a5",
   "metadata": {},
   "source": [
    "*<B>Paths + imports<B>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dfcbd2-cc9a-4900-b177-04fadb8e90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/pattern115/Desktop/1st Year Project\n",
      "RAW_DIR: /Users/pattern115/Desktop/1st Year Project/data/raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# You are inside: instacart-retail-project/notebooks\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "INTERIM_DIR = os.path.join(PROJECT_ROOT, \"data\", \"interim\")\n",
    "PROCESSED_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "\n",
    "os.makedirs(INTERIM_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9580926-0140-477e-8eea-175b0b6ede67",
   "metadata": {},
   "source": [
    "*<B>Confirm raw files exist<B>*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08238d0-d244-41c1-8d28-237b78bfe86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All raw files found.\n"
     ]
    }
   ],
   "source": [
    "expected_files = [\n",
    "    \"orders.csv\",\n",
    "    \"order_products__prior.csv\",\n",
    "    \"order_products__train.csv\",\n",
    "    \"products.csv\",\n",
    "    \"aisles.csv\",\n",
    "    \"departments.csv\",\n",
    "]\n",
    "\n",
    "missing = [f for f in expected_files if not os.path.exists(os.path.join(RAW_DIR, f))]\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing files in data/raw: {missing}\")\n",
    "\n",
    "print(\"✅ All raw files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085ba50-2770-499f-90c5-e5f85806e2c2",
   "metadata": {},
   "source": [
    "*<B>Load CSVs (defines all DFs properly)<B>*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcaaca3a-f073-4b0c-b90f-f1062a137282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders.csv: (3421083, 7)\n",
      "order_products__prior.csv: (32434489, 4)\n",
      "order_products__train.csv: (1384617, 4)\n",
      "products.csv: (49688, 4)\n",
      "aisles.csv: (134, 2)\n",
      "departments.csv: (21, 2)\n",
      "order_products_df: (33819106, 4)\n"
     ]
    }
   ],
   "source": [
    "def load_csv(filename, dtypes=None):\n",
    "    path = os.path.join(RAW_DIR, filename)\n",
    "    df = pd.read_csv(path, dtype=dtypes)\n",
    "    print(f\"{filename}: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "orders_df = load_csv(\"orders.csv\")\n",
    "prior_df = load_csv(\"order_products__prior.csv\")\n",
    "train_df = load_csv(\"order_products__train.csv\")\n",
    "products_df = load_csv(\"products.csv\")\n",
    "aisles_df = load_csv(\"aisles.csv\")\n",
    "departments_df = load_csv(\"departments.csv\")\n",
    "\n",
    "order_products_df = pd.concat([prior_df, train_df], ignore_index=True)\n",
    "print(\"order_products_df:\", order_products_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e70d5e-0f5c-47ca-b85a-1d7086f081ed",
   "metadata": {},
   "source": [
    "*<B>Basic validation checks<B>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72da6bd0-dc52-4b58-bb59-afb177ad69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ orders_df: required columns OK\n",
      "✅ order_products_df: required columns OK\n",
      "✅ products_df: required columns OK\n",
      "\n",
      "Nulls in orders_df:\n",
      " days_since_prior_order    206209\n",
      "order_id                       0\n",
      "user_id                        0\n",
      "eval_set                       0\n",
      "order_number                   0\n",
      "order_dow                      0\n",
      "order_hour_of_day              0\n",
      "dtype: int64\n",
      "\n",
      "Nulls in order_products_df:\n",
      " order_id             0\n",
      "product_id           0\n",
      "add_to_cart_order    0\n",
      "reordered            0\n",
      "dtype: int64\n",
      "\n",
      "Nulls in products_df:\n",
      " product_id       0\n",
      "product_name     0\n",
      "aisle_id         0\n",
      "department_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_required_cols(df, required, name):\n",
    "    missing_cols = [c for c in required if c not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"❌ {name} missing columns: {missing_cols}\")\n",
    "    print(f\"✅ {name}: required columns OK\")\n",
    "\n",
    "check_required_cols(orders_df, [\"order_id\", \"user_id\", \"eval_set\"], \"orders_df\")\n",
    "check_required_cols(order_products_df, [\"order_id\", \"product_id\", \"add_to_cart_order\", \"reordered\"], \"order_products_df\")\n",
    "check_required_cols(products_df, [\"product_id\", \"product_name\", \"aisle_id\", \"department_id\"], \"products_df\")\n",
    "\n",
    "# Quick null scan\n",
    "print(\"\\nNulls in orders_df:\\n\", orders_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "print(\"\\nNulls in order_products_df:\\n\", order_products_df.isna().sum().sort_values(ascending=False).head(10))\n",
    "print(\"\\nNulls in products_df:\\n\", products_df.isna().sum().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb01d27-276a-4f8b-b171-987a614c9d2a",
   "metadata": {},
   "source": [
    "*<B>Save as Parquet*<B>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac984c8-43a1-4b89-8820-5943e9711fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved interim parquet files to: /Users/pattern115/Desktop/1st Year Project/data/interim\n"
     ]
    }
   ],
   "source": [
    "orders_df.to_parquet(os.path.join(INTERIM_DIR, \"orders.parquet\"), index=False)\n",
    "order_products_df.to_parquet(os.path.join(INTERIM_DIR, \"order_products.parquet\"), index=False)\n",
    "products_df.to_parquet(os.path.join(INTERIM_DIR, \"products.parquet\"), index=False)\n",
    "aisles_df.to_parquet(os.path.join(INTERIM_DIR, \"aisles.parquet\"), index=False)\n",
    "departments_df.to_parquet(os.path.join(INTERIM_DIR, \"departments.parquet\"), index=False)\n",
    "\n",
    "print(\"✅ Saved interim parquet files to:\", INTERIM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdae0c-a608-4028-9aa3-d81403b73f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
