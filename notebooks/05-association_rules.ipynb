{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adea8519",
   "metadata": {},
   "source": [
    "# Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10721536",
   "metadata": {},
   "source": [
    "\n",
    "Using the previous notebooks, we performed the following tasks:\n",
    "* Clean EDA\n",
    "\n",
    "* Leakage-free temporal split\n",
    "\n",
    "* Saved parquet files\n",
    "\n",
    "In this notebook we will explore four association rule algorithms:\n",
    "\n",
    "__üîπ Apriori__\n",
    "\n",
    "- Classic frequent itemset mining algorithm.\n",
    "\n",
    "- Uses candidate generation\n",
    "\n",
    "- Works well on small/medium datasets\n",
    "\n",
    "- Easy to interpret\n",
    "\n",
    "_‚ö† Limitation:_\n",
    "\n",
    "- Computationally expensive for large datasets\n",
    "\n",
    "- Only considers frequency\n",
    "\n",
    "__üîπ Eclat__\n",
    "\n",
    "- Uses vertical data format\n",
    "\n",
    "- Depth-first search\n",
    "\n",
    "- More efficient than Apriori in some cases\n",
    "\n",
    "_‚ö† Still frequency-based only._\n",
    "\n",
    "üîπ FP-Growth\n",
    "\n",
    "* Uses FP-tree structure\n",
    "\n",
    "* Avoids candidate generation\n",
    "\n",
    "* More scalable for large datasets\n",
    "\n",
    "Better suited for:\n",
    "\n",
    "* Large retail datasets like Instacart\n",
    "\n",
    "__üîπ UP-Tree (Utility Pattern Mining)__\n",
    "\n",
    "üö® This is the business differentiator.\n",
    "\n",
    "Unlike others:\n",
    "\n",
    "* It considers utility (value/profit)\n",
    "\n",
    "* Not just frequency\n",
    "\n",
    "This allows answering:\n",
    "\n",
    "> Which product combinations generate the most revenue?\n",
    "\n",
    "Instead of:\n",
    "\n",
    "> Which combinations occur most often?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33356e7",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Parquet Files\n",
    "First, we need to load the train/test data set\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c7fdd66ff0c11a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T16:51:14.475058Z",
     "start_time": "2026-02-28T16:51:14.435802Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# You are inside: instacart-retail-project/notebooks\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "INTERIM_DIR = os.path.join(PROJECT_ROOT, \"data\", \"interim\")\n",
    "PROCESSED_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "from modules.association_rules import (\n",
    "    load_temporal_parquets, build_transactions, transactions_to_onehot,\n",
    "    run_apriori, run_fpgrowth, run_eclat, derive_rules_from_itemsets,\n",
    "    rules_to_recommender, evaluate_recommender,evaluate_recommender_proper,\n",
    "    load_product_lookup, attach_product_names, top_rules, enhance_transaction\n",
    ")\n",
    "del evaluate_recommender"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b2d92d61-70e5-4e6a-aa47-324e63d78466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-28T16:52:02.016669Z",
     "start_time": "2026-02-28T16:51:14.479059Z"
    }
   },
   "source": [
    "op_train, op_test = load_temporal_parquets(\n",
    "    os.path.join(PROCESSED_DIR,\"op_train_temporal.parquet\"),\n",
    "    os.path.join(PROCESSED_DIR,\"op_test_temporal.parquet\")\n",
    ")\n",
    "\n",
    "train_tx = build_transactions(op_train)   # Series: order_id -> list(product_id)\n",
    "test_tx  = build_transactions(op_test)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f6df2-ae72-4490-8ce8-a77ce308ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = transactions_to_onehot(train_tx.tolist(), sparse=True)\n",
    "\n",
    "ap = run_apriori(df_onehot, min_support=0.01, metric=\"confidence\", min_threshold=0.3)\n",
    "fp = run_fpgrowth(df_onehot, min_support=0.005, metric=\"confidence\", min_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d98c9521a27fd04",
   "metadata": {},
   "source": [
    "The program crashes here for my computer\n",
    "### ‚ö†Ô∏è Computational Constraint & Product Filtering Strategy\n",
    "#### 1Ô∏è‚É£ Problem: High-Dimensional Transaction Space\n",
    "\n",
    "During the implementation of Apriori and FP-Growth, we encountered computational instability when mining rules at full product granularity.\n",
    "\n",
    "The root cause is structural:\n",
    "\n",
    "The Instacart dataset contains tens of thousands of unique products.\n",
    "\n",
    "One-hot encoding creates a matrix of shape:\n",
    "\n",
    "$ Number of Orders √ó Number of Unique Products$\n",
    "\n",
    "\n",
    "This results in:\n",
    "\n",
    "- Extremely high dimensionality\n",
    "\n",
    "- Large memory consumption\n",
    "\n",
    "- Candidate itemset explosion (especially for Apriori)\n",
    "\n",
    "- Kernel crashes or excessive runtime\n",
    "\n",
    "This is not a modeling issue ‚Äî it is a combinatorial scaling issue inherent to association rule mining in high-dimensional retail data.\n",
    "\n",
    "#### 2Ô∏è‚É£ Structural Insight from Pareto (Long-Tail) Analysis\n",
    "\n",
    "From the Product Distribution & Long Tail analysis, we observed:\n",
    "\n",
    "* A small fraction of products accounts for the majority of purchases.\n",
    "\n",
    "* A large proportion of products are rarely purchased.\n",
    "\n",
    "* The purchase distribution follows a strong Pareto-like pattern.\n",
    "\n",
    "The cumulative coverage curve showed that:\n",
    "\n",
    "* A limited subset of products explains most transaction volume.\n",
    "\n",
    "* The long tail contains thousands of low-frequency items.\n",
    "\n",
    "This means:\n",
    "\n",
    "> Rare products contribute little to global co-occurrence structure but dramatically increase computational complexity.\n",
    "\n",
    "3Ô∏è‚É£ Data-Driven Dimensionality Reduction\n",
    "\n",
    "Instead of arbitrarily reducing the dataset, we applied a Pareto-based filtering strategy:\n",
    "\n",
    "**Strategy:**\n",
    "\n",
    "Keep only products that:\n",
    "\n",
    "* Appear at least 200 times\n",
    "OR\n",
    "* Belong to the top 80% cumulative purchase coverage\n",
    "\n",
    "This ensures that:\n",
    "\n",
    "* We preserve the core transactional structure.\n",
    "\n",
    "* We eliminate extremely sparse dimensions.\n",
    "\n",
    "* We reduce noise.\n",
    "\n",
    "* We prevent combinatorial explosion.\n",
    "\n",
    "We choose to select the to 80% cumulative purchase coverage, and we follow the steps from function enhance_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623d5430500268cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:26:50.824849Z",
     "start_time": "2026-02-27T09:26:48.822823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage_target': 0.8, 'original_products': 49677, 'retained_products': 4537, 'original_transactions': 3214874, 'retained_transactions': 3151193, 'purchase_volume_retained': 0.8, 'dimensionality_reduction_ratio': 0.9087}\n"
     ]
    }
   ],
   "source": [
    "# Keep 80% coverage\n",
    "op_train_filtered, stats = enhance_transaction(op_train, coverage=0.80)\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbe71fcae9ed23",
   "metadata": {},
   "source": [
    "Now rebuild transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843646fab4774534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:27:50.637425Z",
     "start_time": "2026-02-27T09:26:52.900333Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tx = build_transactions(op_train_filtered)\n",
    "df_onehot = transactions_to_onehot(train_tx.tolist(), sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fcb74cfa32410",
   "metadata": {},
   "source": [
    "Now, I can run Apriori and FP-Growth Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dab24c2d6898aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T22:46:00.312940Z",
     "start_time": "2026-02-26T22:18:27.605528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'apriori',\n",
       " 'min_support': 0.005,\n",
       " 'metric': 'confidence',\n",
       " 'min_threshold': 0.3,\n",
       " 'n_itemsets': 338,\n",
       " 'n_rules': 5,\n",
       " 'runtime_sec': 1652.6259}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = run_apriori(df_onehot, min_support=0.005, metric=\"confidence\", min_threshold=0.3)\n",
    "\n",
    "\n",
    "ap.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1e616a26d21ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T22:53:30.910910Z",
     "start_time": "2026-02-26T22:51:13.096573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'fp-growth',\n",
       " 'min_support': 0.005,\n",
       " 'metric': 'confidence',\n",
       " 'min_threshold': 0.3,\n",
       " 'n_itemsets': 338,\n",
       " 'n_rules': 5,\n",
       " 'runtime_sec': 137.7508}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = run_fpgrowth(df_onehot, min_support=0.005, metric=\"confidence\", min_threshold=0.3)\n",
    "\n",
    "\n",
    "fp.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc18da526d52d6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ded7bdad6c5231d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T22:54:03.728650Z",
     "start_time": "2026-02-26T22:53:35.744511Z"
    }
   },
   "outputs": [],
   "source": [
    "ec = run_eclat(train_tx, min_support=0.005, max_len=3)\n",
    "ec_rules = derive_rules_from_itemsets(\n",
    "    ec.frequent_itemsets,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5a0875584c12d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75ae364dc2e3382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T23:03:25.998965Z",
     "start_time": "2026-02-26T23:02:56.370309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori: {'HitRate@K': 0.012447332025344955, 'Precision@K': 0.0012447332025344593, 'Recall@K': 0.001903592585106979}\n",
      "FP-Growth: {'HitRate@K': 0.012447332025344955, 'Precision@K': 0.0012447332025344593, 'Recall@K': 0.001903592585106979}\n",
      "Eclat: {'HitRate@K': 0.012447332025344955, 'Precision@K': 0.0012447332025344593, 'Recall@K': 0.001903592585106979}\n"
     ]
    }
   ],
   "source": [
    "ap_rules_ranked = rules_to_recommender(ap.rules, sort_by=\"lift\")\n",
    "fp_rules_ranked = rules_to_recommender(fp.rules, sort_by=\"lift\")\n",
    "ec_rules_ranked = rules_to_recommender(ec_rules, sort_by=\"lift\")\n",
    "\n",
    "print(\"Apriori:\", evaluate_recommender_proper(ap_rules_ranked, test_tx, k=10))\n",
    "print(\"FP-Growth:\", evaluate_recommender_proper(fp_rules_ranked, test_tx, k=10))\n",
    "print(\"Eclat:\", evaluate_recommender_proper(ec_rules_ranked, test_tx, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db29f4d1012a3c7",
   "metadata": {},
   "source": [
    "As we see most Algorithms resulted in:\n",
    "\n",
    "* HitRate@K ‚âà 1.2%\n",
    "* Precision@K ‚âà 0.12%\n",
    "* Recall@K ‚âà 0.19%\n",
    "\n",
    "Which is a very low, and identical across **Apriori, FP-Growth and Eclat**, All three algorithms find the same frequent patterns (which is normal). So improving performance means improving:\n",
    "\n",
    "* Data preparation\n",
    "* Rule filtering\n",
    "* Recommendation strategy\n",
    "* Evaluation setup\n",
    "\n",
    "Let‚Äôs go step by step.\n",
    "#### üî• 1Ô∏è‚É£ Why Are The Scores Low?\n",
    "\n",
    "Association rules for next-basket prediction are naturally weak because:\n",
    "\n",
    "* They are global (not personalized)\n",
    "* They don‚Äôt use user history depth\n",
    "* They don‚Äôt rank intelligently\n",
    "* They don‚Äôt optimize for prediction directly\n",
    "\n",
    "But 1.2% hit rate is very low ‚Äî we can improve.\n",
    "\n",
    "#### üöÄ STRATEGY TO IMPROVE PERFORMANCE\n",
    "\n",
    "To improve the results of our algorithms we need to work on 5 layers.\n",
    "\n",
    "__‚úÖ STEP 1 ‚Äî Tune min_support & min_confidence__\n",
    "\n",
    "Right we are using:\n",
    "<code>\n",
    "min_support = 0.005\n",
    "min_threshold = 0.3\n",
    "</code>\n",
    "That might be too strict.\n",
    "\n",
    "Try:\n",
    "<code>\n",
    "min_support = 0.003\n",
    "min_threshold = 0.2\n",
    "</code>\n",
    "Then evaluate again.\n",
    "\n",
    "Once we change these values we can re-evaluate our algorithms.\n",
    "\n",
    "__‚úÖ STEP 2 ‚Äî Filter Rules Smartly__\n",
    "\n",
    "Instead of using all rules, filter them.\n",
    "\n",
    "For example:\n",
    "\n",
    "Keep only rules with:\n",
    "\n",
    "* lift > 1.1\n",
    "* confidence > 0.25\n",
    "* support > 0.002\n",
    "\n",
    "<code>\n",
    "filtered_rules = ap.rules[\n",
    "    (ap.rules[\"lift\"] > 1.1) &\n",
    "    (ap.rules[\"confidence\"] > 0.25)\n",
    "]\n",
    "</code>\n",
    "\n",
    "Then rank by lift, Often improves hit rate.\n",
    "\n",
    "__‚úÖ STEP 3 ‚Äî Use Multi-Item Antecedents__\n",
    "\n",
    "Right now we are using many single-item rules.\n",
    "\n",
    "But better predictive power often comes from:\n",
    "\n",
    "* 2-item antecedents\n",
    "* 3-item antecedents\n",
    "\n",
    "Therefore we need to Filter using:\n",
    "<code>\n",
    "ap.rules[\"ante_len\"] = ap.rules[\"antecedents\"].apply(len)\n",
    "\n",
    "rules_multi = ap.rules[ap.rules[\"ante_len\"] >= 2]\n",
    "</code>\n",
    "Single-item rules are often too generic.\n",
    "\n",
    "__‚úÖ STEP 4 ‚Äî Better Recommendation Strategy__\n",
    "\n",
    "Right now our recommender likely:\n",
    "\n",
    "* Iterates rules\n",
    "\n",
    "* Stops at first matches\n",
    "\n",
    "And this is weak.\n",
    "\n",
    "Instead:\n",
    "\n",
    "*Score consequents by weighted score:*\n",
    "\n",
    "For each rule that matches:\n",
    "\n",
    "$Score = confidence √ó lift$\n",
    "\n",
    "Aggregate scores per recommended product.\n",
    "\n",
    "A better recommender is described on function: `recommend_weighted`.\n",
    "This alone can significantly improve performance.\n",
    "\n",
    "__‚úÖ STEP 5 ‚Äî Personalization (Major Boost)__\n",
    "\n",
    "Association rules are global. But users have history.\n",
    "\n",
    "Instead of using only observed basket, use:\n",
    "\n",
    "* All previous purchases of that user (from train)\n",
    "\n",
    "We can build user profile:\n",
    "\n",
    "`user_history = op_train.groupby(\"user_id\")[\"product_id\"].apply(set)`\n",
    "\n",
    "Then we can use:\n",
    "\n",
    "`observed = user_history[user_id]`\n",
    "\n",
    "That dramatically increases hit rate.\n",
    "Let's apply all these modifications and evaluate our algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356eda4f40c80e3",
   "metadata": {},
   "source": [
    "### Run the improved pipeline (Apriori / FP / Eclat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c8688468e6ad3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:28:03.594401Z",
     "start_time": "2026-02-27T09:28:03.576310Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Lower support slightly (example: 0.003 instead of 0.005)\n",
    "MIN_SUPPORT = 0.003\n",
    "MIN_CONF    = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd77fb20889a0a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:33:37.395176Z",
     "start_time": "2026-02-27T09:28:12.598799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build one-hot on TRAIN (we use sparse=True to reduce memory)\n",
    "# Use the Pareto data\n",
    "# df_onehot = transactions_to_onehot(train_tx.tolist(), sparse=True)\n",
    "\n",
    "# ---- Apriori ----\n",
    "ap = run_apriori(\n",
    "    df_onehot,\n",
    "    min_support=MIN_SUPPORT,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=MIN_CONF,\n",
    "    max_len=3  # We keep it small for scalability; we can try 4 later\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "480489f059829f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:36:09.262149Z",
     "start_time": "2026-02-27T10:33:37.412939Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- FP-Growth ----\n",
    "fp = run_fpgrowth(\n",
    "    df_onehot,\n",
    "    min_support=MIN_SUPPORT,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=MIN_CONF,\n",
    "    max_len=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cd4149c2306a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:37:00.782281Z",
     "start_time": "2026-02-27T10:36:09.264669Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Eclat ---- (itemsets then derive rules)\n",
    "ec = run_eclat(\n",
    "    train_tx,\n",
    "    min_support=MIN_SUPPORT,\n",
    "    max_len=3\n",
    ")\n",
    "ec_rules = derive_rules_from_itemsets(\n",
    "    ec.frequent_itemsets,\n",
    "    metric=\"confidence\",\n",
    "    min_threshold=MIN_CONF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3e7d8e039443cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:37:00.902160Z",
     "start_time": "2026-02-27T10:37:00.794548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules after filtering:\n",
      "Apriori: 14 | FP-Growth: 14 | Eclat: 14\n"
     ]
    }
   ],
   "source": [
    "from modules.association_rules import filter_rules_for_prediction, evaluate_weighted_recommender\n",
    "# 3Ô∏è‚É£ Filter rules with lift > 1\n",
    "# 4Ô∏è‚É£ Use multi-item antecedents (len >= 2)\n",
    "ap_f = filter_rules_for_prediction(ap.rules, min_lift=1.0, min_confidence=MIN_CONF, min_antecedent_len=2)\n",
    "fp_f = filter_rules_for_prediction(fp.rules, min_lift=1.0, min_confidence=MIN_CONF, min_antecedent_len=2)\n",
    "ec_f = filter_rules_for_prediction(ec_rules,   min_lift=1.0, min_confidence=MIN_CONF, min_antecedent_len=2)\n",
    "\n",
    "print(\"Rules after filtering:\")\n",
    "print(\"Apriori:\", len(ap_f), \"| FP-Growth:\", len(fp_f), \"| Eclat:\", len(ec_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6826971afca57f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:38:03.852151Z",
     "start_time": "2026-02-27T10:37:00.916395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apriori: {'HitRate@K': 0.007735357498954681, 'Precision@K': 0.0007984625775947925, 'Recall@K': 0.0009941800009024239, 'n_eval_orders': 124364}\n",
      "FP-Growth: {'HitRate@K': 0.007735357498954681, 'Precision@K': 0.0007984625775947925, 'Recall@K': 0.0009941800009024239, 'n_eval_orders': 124364}\n",
      "Eclat: {'HitRate@K': 0.007735357498954681, 'Precision@K': 0.0007984625775947925, 'Recall@K': 0.0009941800009024239, 'n_eval_orders': 124364}\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Weighted recommender + 5Ô∏è‚É£ Evaluate again\n",
    "K = 10\n",
    "HIDE_RATIO = 0.5\n",
    "\n",
    "ap_eval = evaluate_weighted_recommender(ap_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"conf_lift\")\n",
    "fp_eval = evaluate_weighted_recommender(fp_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"conf_lift\")\n",
    "ec_eval = evaluate_weighted_recommender(ec_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"conf_lift\")\n",
    "\n",
    "print(\"Apriori:\", ap_eval)\n",
    "print(\"FP-Growth:\", fp_eval)\n",
    "print(\"Eclat:\", ec_eval) # Optional: Try scoring modes\n",
    "# print(evaluate_weighted_recommender(ap_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"conf\"))\n",
    "# print(evaluate_weighted_recommender(ap_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"lift\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576878d7945d22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_lookup = load_product_lookup(\"products.csv\")\n",
    "ap_named = attach_product_names(ap_rules_ranked, products_lookup)\n",
    "\n",
    "top_rules(ap_named, sort_by=\"lift\", n=15)[\n",
    "    [\"antecedents_names\",\"consequents_names\",\"support\",\"confidence\",\"lift\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f09a4bf5306b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Try scoring modes\n",
    "# print(evaluate_weighted_recommender(ap_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"conf\"))\n",
    "# print(evaluate_weighted_recommender(ap_f, test_tx, k=K, hide_ratio=HIDE_RATIO, score_mode=\"lift\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf601860f35f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.association_rules import build_spmf_utility_file, run_uptree_spmf\n",
    "\n",
    "# Example: utility = price (or price * quantity if you had quantities)\n",
    "prices = pd.read_csv(\"api_prices.csv\")  # must contain product_id, price\n",
    "op_train_u = op_train.merge(prices, on=\"product_id\", how=\"left\")\n",
    "op_train_u[\"price\"] = op_train_u[\"price\"].fillna(0.0)\n",
    "op_train_u[\"utility\"] = op_train_u[\"price\"]\n",
    "\n",
    "build_spmf_utility_file(op_train_u, \"instacart_utility.txt\")\n",
    "\n",
    "res_upt = run_uptree_spmf(\n",
    "    spmf_jar_path=\"spmf.jar\",\n",
    "    input_utility_file=\"instacart_utility.txt\",\n",
    "    output_file=\"uptree_output.txt\",\n",
    "    min_utility=10000,\n",
    "    item_separator=\" \"\n",
    ")\n",
    "\n",
    "res_upt.meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
