{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7894a3-5bd6-4632-a4e9-a253c9f34d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkEnrichment\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77aa034d-9f33-4866-963f-5c816d62ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(5).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575bceb9-9170-48d0-bb11-ca2273e1f844",
   "metadata": {},
   "source": [
    "### Load Cleaned Transactions Dataset\n",
    "\n",
    "This cell loads the cleaned transaction data produced in the previous notebook.\n",
    "\n",
    "The dataset is stored in Parquet format for efficient reading and consistent schema.\n",
    "A smal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e01019-c984-4906-a01b-55ec68a1bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+----------+\n",
      "|product_id|order_id|add_to_cart_order|reordered|department_id|aisle_id|        product_name|               aisle|department|\n",
      "+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+----------+\n",
      "|     48370|       5|                6|        1|           17|      54|Sensitive Toilet ...|         paper goods| household|\n",
      "|     10096|      14|                8|        1|            1|      58|Corn Meal Pizza C...|frozen breads doughs|    frozen|\n",
      "|     16974|      35|                4|        0|           19|     107|Sea Salt Brown Ri...|      chips pretzels|    snacks|\n",
      "|     16974|      61|               12|        1|           19|     107|Sea Salt Brown Ri...|      chips pretzels|    snacks|\n",
      "|     18306|      84|                9|        0|            7|      94|Chai Green Tea Ba...|                 tea| beverages|\n",
      "+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32434489"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = spark.read.parquet(\"../data_clean/transactions\")\n",
    "\n",
    "transactions.show(5)\n",
    "transactions.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe5baa-4a46-4a68-b581-2aa0db9573b2",
   "metadata": {},
   "source": [
    "### Load External Pricing Data\n",
    "\n",
    "This cell loads external pricing data that simulates information retrieved from an API.\n",
    "\n",
    "The pricing dataset contains average product prices by department.\n",
    "This data will be used to enrich the transaction dataset with monetary values.\n",
    "\n",
    "Displaying the data helps verify that the pricing information was loaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27119c9-4925-445d-b415-bd98889b8221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|department|avg_price|\n",
      "+----------+---------+\n",
      "|   produce|      1.5|\n",
      "|dairy eggs|      2.5|\n",
      "|    snacks|      2.0|\n",
      "| beverages|      1.8|\n",
      "|    frozen|      3.0|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prices_df = spark.read.csv(\n",
    "    \"../data_raw/api_prices.csv\",\n",
    "    header=True\n",
    ")\n",
    "\n",
    "prices_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954521fe-d862-435c-a0ba-310c7504be14",
   "metadata": {},
   "source": [
    "### Enrich Transactions with Pricing Information\n",
    "\n",
    "This cell joins the cleaned transaction data with external pricing data.\n",
    "\n",
    "- Transactions are joined with prices using the `department` field\n",
    "- A left join ensures all transactions are retained\n",
    "- Average price information is added to each transaction\n",
    "\n",
    "This enrichment step enables revenue-based analysis in later stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3efbb201-6818-4dbc-8c00-c1f7a3838281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+---------+\n",
      "|department|product_id|order_id|add_to_cart_order|reordered|department_id|aisle_id|        product_name|               aisle|avg_price|\n",
      "+----------+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+---------+\n",
      "| household|     48370|       5|                6|        1|           17|      54|Sensitive Toilet ...|         paper goods|     NULL|\n",
      "|    frozen|     10096|      14|                8|        1|            1|      58|Corn Meal Pizza C...|frozen breads doughs|      3.0|\n",
      "|    snacks|     16974|      35|                4|        0|           19|     107|Sea Salt Brown Ri...|      chips pretzels|      2.0|\n",
      "|    snacks|     16974|      61|               12|        1|           19|     107|Sea Salt Brown Ri...|      chips pretzels|      2.0|\n",
      "| beverages|     18306|      84|                9|        0|            7|      94|Chai Green Tea Ba...|                 tea|      1.8|\n",
      "+----------+----------+--------+-----------------+---------+-------------+--------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "transactions_enriched = transactions.join(\n",
    "    prices_df,\n",
    "    on=\"department\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "transactions_enriched.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d18aa-2e85-4aba-81fd-000337556983",
   "metadata": {},
   "source": [
    "### Clean and Standardize Pricing Data\n",
    "\n",
    "This cell ensures the pricing information is usable for analysis.\n",
    "\n",
    "- The `avg_price` column is cast to a numeric type\n",
    "- Missing prices are filled with a default average value\n",
    "\n",
    "This step prevents errors in downstream calculations and ensures all transactions have a monetary value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd88d36-0dc5-48ec-8010-2d47d1d7596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_enriched = transactions_enriched.withColumn(\n",
    "    \"avg_price\",\n",
    "    col(\"avg_price\").cast(\"double\")\n",
    ")\n",
    "\n",
    "transactions_enriched = transactions_enriched.fillna(\n",
    "    {\"avg_price\": 2.0}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb114e11-4f07-4b5b-a7e9-6a3a05d0169f",
   "metadata": {},
   "source": [
    "### Create Sample Dataset for Analysis\n",
    "\n",
    "This cell creates a smaller, representative sample of the enriched transaction data.\n",
    "\n",
    "Sampling reduces data size, making experimentation and analysis faster.\n",
    "A fixed random seed is used to ensure the sample is reproducible.\n",
    "\n",
    "This sampled dataset is intended for data science and analysis tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ca3165-22b8-49d6-8f25-000f079d4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_enriched = transactions_enriched.sample(\n",
    "    fraction=0.1,   # 10% sample\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262d0ef-08eb-4b8a-a20d-3b74629c7f10",
   "metadata": {},
   "source": [
    "### Optimize Data Partitions for Local Processing\n",
    "\n",
    "This cell adjusts the number of partitions in the enriched dataset.\n",
    "\n",
    "Repartitioning helps balance workload and improves performance when working locally.\n",
    "Using a small number of partitions is suitable for development and analysis on a single machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f677f28-03ce-49c9-8414-09fee4ccc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_enriched = transactions_enriched.repartition(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd2a3b-e2c6-4fdb-820b-01f1af334c87",
   "metadata": {},
   "source": [
    "### Prepare Output Directory for Enriched Data\n",
    "\n",
    "This cell ensures that the directory for storing enriched datasets exists.\n",
    "\n",
    "Creating the directory in advance prevents write errors when saving data.\n",
    "This step supports a clean and organized project structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f968d631-5e08-44ed-aede-546f0fb6b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../data_enriched\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4401d8-1241-43c5-8d48-1f4527ba99f2",
   "metadata": {},
   "source": [
    "### Persist Enriched Transactions Dataset\n",
    "\n",
    "This cell writes the enriched transaction data to disk in Parquet format.\n",
    "\n",
    "The dataset now includes pricing information and is optimized for analytics.\n",
    "Overwrite mode allows the dataset to be regenerated during development.\n",
    "\n",
    "This output represents the final handoff from data engineering to data science and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e091399-3d74-4986-93f3-132f3dce14d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "transactions_enriched.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"../data_enriched/transactions_enriched\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8ccad4-5943-4b43-b1d7-5ea3150afe90",
   "metadata": {},
   "source": [
    "### Verify Enriched Data Output Files\n",
    "\n",
    "This cell lists the contents of the enriched data directories.\n",
    "\n",
    "It confirms that the Parquet files were successfully written to disk.\n",
    "Seeing multiple part files indicates that Spark saved the data correctly in distributed format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d64b56-0db9-480c-9d98-7998fe1b8a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-68bc476e-dd89-4f66-acc7-00b26880e312-c000.snappy.parquet',\n",
       " '._SUCCESS.crc',\n",
       " '.part-00001-68bc476e-dd89-4f66-acc7-00b26880e312-c000.snappy.parquet.crc',\n",
       " 'part-00001-68bc476e-dd89-4f66-acc7-00b26880e312-c000.snappy.parquet',\n",
       " '_SUCCESS',\n",
       " '.part-00000-68bc476e-dd89-4f66-acc7-00b26880e312-c000.snappy.parquet.crc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../data_enriched\")\n",
    "os.listdir(\"../data_enriched/transactions_enriched\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02f6b9-df2e-4999-9089-e1578963ae05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
